{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fine-Tuning BART for Abstractive Summarization on Kaggle\n",
                "\n",
                "This notebook fine-tunes `facebook/bart-large-cnn` on the processed CNN/DailyMail dataset.\n",
                "It is configured to run on Kaggle with a T4 GPU."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Missing Dependencies Only\n",
                "# We avoid re-installing transformers/torch to prevent breaking Kaggle's pre-installed environment\n",
                "!pip install -q datasets evaluate rouge_score accelerate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Imports and Setup\n",
                "import os\n",
                "import numpy as np\n",
                "import torch\n",
                "import evaluate\n",
                "import nltk\n",
                "from pathlib import Path\n",
                "from datasets import load_from_disk\n",
                "from transformers import (\n",
                "    AutoTokenizer, \n",
                "    AutoModelForSeq2SeqLM, \n",
                "    DataCollatorForSeq2Seq, \n",
                "    Seq2SeqTrainingArguments, \n",
                "    Seq2SeqTrainer\n",
                ")\n",
                "\n",
                "# Download NLTK data for ROUGE\n",
                "nltk.download('punkt', quiet=True)\n",
                "\n",
                "print(\"Libraries installed and imported.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Configuration\n",
                "# User specified input path on Kaggle\n",
                "PROCESSED_DATA_PATH = Path(\"/kaggle/input/cnn-dailymail-processed/cnn_dailymail_processed\")\n",
                "MODEL_CHECKPOINT = \"facebook/bart-large-cnn\"\n",
                "OUTPUT_DIR = Path(\"/kaggle/working/models/checkpoints\")\n",
                "FINAL_MODEL_DIR = Path(\"/kaggle/working/models/final_model_full\")\n",
                "\n",
                "print(f\"Data Path: {PROCESSED_DATA_PATH}\")\n",
                "print(f\"Model Output: {FINAL_MODEL_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Define Metrics (ROUGE)\n",
                "metric = evaluate.load(\"rouge\")\n",
                "\n",
                "def compute_metrics(eval_pred, tokenizer):\n",
                "    predictions, labels = eval_pred\n",
                "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
                "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
                "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
                "    \n",
                "    # Rouge expects newline after each sentence\n",
                "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
                "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
                "    \n",
                "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
                "    return {k: round(v * 100, 4) for k, v in result.items()}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Training Function\n",
                "def train():\n",
                "    if not PROCESSED_DATA_PATH.exists():\n",
                "        raise FileNotFoundError(f\"Dataset not found at {PROCESSED_DATA_PATH}. Please check the input path.\")\n",
                "\n",
                "    print(f\"Loading data from {PROCESSED_DATA_PATH}...\")\n",
                "    tokenized_datasets = load_from_disk(str(PROCESSED_DATA_PATH))\n",
                "    \n",
                "    print(\"Loading model and tokenizer...\")\n",
                "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
                "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\n",
                "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
                "    \n",
                "    # --- CRITICAL OPTIMIZATION ---\n",
                "    # Defaulting to 25% of data to ensure completion within Kaggle 12h limit\n",
                "    # 25% of ~287k samples = ~71k samples (Approx 5-6 hours on T4)\n",
                "    print(\"Subsampling dataset to 25% to fit in time limit...\")\n",
                "    tokenized_datasets[\"train\"] = tokenized_datasets[\"train\"].shard(num_shards=4, index=0)\n",
                "    print(f\"New Training Samples: {len(tokenized_datasets['train'])}\")\n",
                "    # -----------------------------\n",
                "\n",
                "    # TRAINING ARGUMENTS\n",
                "    # Configured for T4 GPU (16GB VRAM)\n",
                "    training_args = Seq2SeqTrainingArguments(\n",
                "        output_dir=str(OUTPUT_DIR),\n",
                "        eval_strategy=\"epoch\",\n",
                "        save_strategy=\"epoch\",\n",
                "        learning_rate=2e-5,\n",
                "        per_device_train_batch_size=4,\n",
                "        per_device_eval_batch_size=4,\n",
                "        gradient_accumulation_steps=8,  # Effective batch size = 32\n",
                "        weight_decay=0.01,\n",
                "        save_total_limit=1,\n",
                "        num_train_epochs=1,  # Set to 1 safe run, increase if you have quota\n",
                "        predict_with_generate=True,\n",
                "        fp16=True, \n",
                "        logging_steps=50,\n",
                "        report_to=\"none\",\n",
                "    )\n",
                "\n",
                "    trainer = Seq2SeqTrainer(\n",
                "        model=model,\n",
                "        args=training_args,\n",
                "        train_dataset=tokenized_datasets[\"train\"],\n",
                "        eval_dataset=tokenized_datasets[\"validation\"],\n",
                "        tokenizer=tokenizer,\n",
                "        data_collator=data_collator,\n",
                "        compute_metrics=lambda eval_pred: compute_metrics(eval_pred, tokenizer),\n",
                "    )\n",
                "\n",
                "    print(\"Starting training...\")\n",
                "    trainer.train()\n",
                "\n",
                "    print(f\"Saving final model to {FINAL_MODEL_DIR}...\")\n",
                "    trainer.save_model(str(FINAL_MODEL_DIR))\n",
                "    tokenizer.save_pretrained(str(FINAL_MODEL_DIR))\n",
                "    print(\"Model saved successfully.\")\n",
                "\n",
                "# Run Training\n",
                "if __name__ == \"__main__\":\n",
                "    train()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Zip Output for Download\n",
                "!zip -r /kaggle/working/final_model.zip /kaggle/working/models/final_model_full\n",
                "print(\"\\nDone! You can now download 'final_model.zip' from the Output tab.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}